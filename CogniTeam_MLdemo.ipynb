{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainwave Frequencies:\n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/ML101_KS.csv . ( 1  of  16 )\n",
      "234  frames generated with label  1 .234Interpolating 110/234Interpolating 167/234Interpolating 219/234\n",
      "\n",
      "\n",
      "Processing session:  data/ML101_US.csv . ( 2  of  16 )\n",
      "224  frames generated with label  0 .224Interpolating 85/224Interpolating 124/224Interpolating 173/224\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_KS.csv . ( 3  of  16 )\n",
      "222  frames generated with label  1 .222Interpolating 95/222Interpolating 132/222Interpolating 186/222\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_US.csv . ( 4  of  16 )\n",
      "218  frames generated with label  0 .218Interpolating 102/218Interpolating 147/218Interpolating 207/218\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_KS.csv . ( 5  of  16 )\n",
      "226  frames generated with label  1 .226Interpolating 92/226Interpolating 118/226Interpolating 174/226Interpolating 219/226\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_US.csv . ( 6  of  16 )\n",
      "208  frames generated with label  0 .208Interpolating 120/208Interpolating 169/208\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_KS.csv . ( 7  of  16 )\n",
      "202  frames generated with label  1 .202Interpolating 108/202Interpolating 170/202\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_US.csv . ( 8  of  16 )\n",
      "204  frames generated with label  0 .204Interpolating 110/204\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_KS.csv . ( 9  of  16 )\n",
      "214  frames generated with label  1 .214Interpolating 126/214Interpolating 172/214\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_US.csv . ( 10  of  16 )\n",
      "226  frames generated with label  0 .226Interpolating 124/226Interpolating 174/226\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_KS.csv . ( 11  of  16 )\n",
      "230  frames generated with label  1 .230Interpolating 97/230Interpolating 152/230Interpolating 204/230\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_US.csv . ( 12  of  16 )\n",
      "278  frames generated with label  0 .278Interpolating 121/278Interpolating 183/278Interpolating 238/278\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_KS.csv . ( 13  of  16 )\n",
      "246  frames generated with label  1 .246Interpolating 119/246Interpolating 172/246Interpolating 230/246\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_US.csv . ( 14  of  16 )\n",
      "236  frames generated with label  0 .236Interpolating 77/236Interpolating 132/236Interpolating 177/236Interpolating 218/236\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_KS.csv . ( 15  of  16 )\n",
      "240  frames generated with label  1 .240Interpolating 97/240Interpolating 140/240Interpolating 198/240\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_US.csv . ( 16  of  16 )\n",
      "234  frames generated with label  0 .234Interpolating 100/234Interpolating 146/234Interpolating 191/234Interpolating 232/234\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Beta')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_pipeline\n",
    "#from https://github.com/tevisgehr/EEG-Classification\n",
    "from eeg_learn_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4\n",
    "\n",
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta\n",
    "\n",
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals\n",
    "\n",
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]\n",
    "\n",
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN:\n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "\n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "\n",
    "    print('Generating training data...')\n",
    "\n",
    "\n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',').T\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "\n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "\n",
    "\n",
    "    return X,np.array(y)\n",
    "\n",
    "file_names = ['data/ML101_KS.csv',\n",
    "              'data/ML101_US.csv',\n",
    "              'data/ML102_KS.csv',\n",
    "              'data/ML102_US.csv',\n",
    "              'data/ML103_KS.csv',\n",
    "              'data/ML103_US.csv',\n",
    "              'data/ML104_KS.csv',\n",
    "              'data/ML104_US.csv',\n",
    "              'data/ML105_KS.csv',\n",
    "              'data/ML105_US.csv',\n",
    "              'data/ML106_KS.csv',\n",
    "              'data/ML106_US.csv',\n",
    "              'data/ML107_KS.csv',\n",
    "              'data/ML107_US.csv',\n",
    "              'data/ML108_KS.csv',\n",
    "              'data/ML108_US.csv']\n",
    "labels = [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "image_size = 28\n",
    "frame_duration = 1.0\n",
    "overlap = 0.5\n",
    "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X[0][:,:,0], cmap='nipy_spectral')\n",
    "plt.title('Theta')\n",
    "plt.imshow(X[0][:,:,1], cmap='nipy_spectral')\n",
    "plt.title('Alpha')\n",
    "plt.imshow(X[0][:,:,2], cmap='nipy_spectral')\n",
    "plt.title('Beta')\n",
    "#plt.colorbar(extend='both')\n",
    "#plt.clim(-0.001, 0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2913, 28, 28, 3)\n",
      "2913 train samples\n",
      "729 test samples\n",
      "Train on 2913 samples, validate on 729 samples\n",
      "Epoch 1/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6981 - accuracy: 0.4978 - val_loss: 0.6866 - val_accuracy: 0.5199\n",
      "Epoch 2/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6952 - accuracy: 0.5146 - val_loss: 0.6858 - val_accuracy: 0.5610\n",
      "Epoch 3/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6920 - accuracy: 0.5252 - val_loss: 0.6863 - val_accuracy: 0.5158\n",
      "Epoch 4/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6848 - accuracy: 0.5359 - val_loss: 0.6855 - val_accuracy: 0.5364\n",
      "Epoch 5/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6881 - accuracy: 0.5328 - val_loss: 0.6820 - val_accuracy: 0.5377\n",
      "Epoch 6/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6857 - accuracy: 0.5376 - val_loss: 0.6808 - val_accuracy: 0.5514\n",
      "Epoch 7/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6790 - accuracy: 0.5503 - val_loss: 0.6762 - val_accuracy: 0.5364\n",
      "Epoch 8/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6787 - accuracy: 0.5558 - val_loss: 0.6737 - val_accuracy: 0.5473\n",
      "Epoch 9/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6752 - accuracy: 0.5647 - val_loss: 0.6855 - val_accuracy: 0.5213\n",
      "Epoch 10/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6724 - accuracy: 0.5829 - val_loss: 0.6720 - val_accuracy: 0.5364\n",
      "Epoch 11/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6682 - accuracy: 0.5870 - val_loss: 0.6644 - val_accuracy: 0.5789\n",
      "Epoch 12/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6648 - accuracy: 0.5884 - val_loss: 0.6857 - val_accuracy: 0.5926\n",
      "Epoch 13/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6582 - accuracy: 0.5984 - val_loss: 0.6747 - val_accuracy: 0.5734\n",
      "Epoch 14/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6525 - accuracy: 0.6093 - val_loss: 0.6578 - val_accuracy: 0.5706\n",
      "Epoch 15/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6473 - accuracy: 0.5987 - val_loss: 0.6598 - val_accuracy: 0.5720\n",
      "Epoch 16/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6474 - accuracy: 0.6073 - val_loss: 0.6527 - val_accuracy: 0.5912\n",
      "Epoch 17/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6379 - accuracy: 0.6186 - val_loss: 0.6537 - val_accuracy: 0.6132\n",
      "Epoch 18/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.6411 - accuracy: 0.6135 - val_loss: 0.6361 - val_accuracy: 0.6255\n",
      "Epoch 19/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6342 - accuracy: 0.6214 - val_loss: 0.6449 - val_accuracy: 0.5885\n",
      "Epoch 20/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.6274 - accuracy: 0.6272 - val_loss: 0.6314 - val_accuracy: 0.6036\n",
      "Epoch 21/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6279 - accuracy: 0.6320 - val_loss: 0.6547 - val_accuracy: 0.6022\n",
      "Epoch 22/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6087 - accuracy: 0.6430 - val_loss: 0.6457 - val_accuracy: 0.5995\n",
      "Epoch 23/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6165 - accuracy: 0.6395 - val_loss: 0.6722 - val_accuracy: 0.5734\n",
      "Epoch 24/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6040 - accuracy: 0.6560 - val_loss: 0.6274 - val_accuracy: 0.6145\n",
      "Epoch 25/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6020 - accuracy: 0.6574 - val_loss: 0.6205 - val_accuracy: 0.6502\n",
      "Epoch 26/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6029 - accuracy: 0.6591 - val_loss: 0.6242 - val_accuracy: 0.6529\n",
      "Epoch 27/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5882 - accuracy: 0.6632 - val_loss: 0.6337 - val_accuracy: 0.6296\n",
      "Epoch 28/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5929 - accuracy: 0.6680 - val_loss: 0.6259 - val_accuracy: 0.6406\n",
      "Epoch 29/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5825 - accuracy: 0.6797 - val_loss: 0.6565 - val_accuracy: 0.6187\n",
      "Epoch 30/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5835 - accuracy: 0.6739 - val_loss: 0.6100 - val_accuracy: 0.6379\n",
      "Epoch 31/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5661 - accuracy: 0.6811 - val_loss: 0.6475 - val_accuracy: 0.6255\n",
      "Epoch 32/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5861 - accuracy: 0.6711 - val_loss: 0.6219 - val_accuracy: 0.6475\n",
      "Epoch 33/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5625 - accuracy: 0.6917 - val_loss: 0.6081 - val_accuracy: 0.6557\n",
      "Epoch 34/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5614 - accuracy: 0.6938 - val_loss: 0.6099 - val_accuracy: 0.6447\n",
      "Epoch 35/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5663 - accuracy: 0.6928 - val_loss: 0.6309 - val_accuracy: 0.6420\n",
      "Epoch 36/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5522 - accuracy: 0.7020 - val_loss: 0.6087 - val_accuracy: 0.6420\n",
      "Epoch 37/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5563 - accuracy: 0.7003 - val_loss: 0.6364 - val_accuracy: 0.6475\n",
      "Epoch 38/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5532 - accuracy: 0.6976 - val_loss: 0.6157 - val_accuracy: 0.6337\n",
      "Epoch 39/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5385 - accuracy: 0.7099 - val_loss: 0.5983 - val_accuracy: 0.6626\n",
      "Epoch 40/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5359 - accuracy: 0.7154 - val_loss: 0.6066 - val_accuracy: 0.6612\n",
      "Epoch 41/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5577 - accuracy: 0.7024 - val_loss: 0.5716 - val_accuracy: 0.6790\n",
      "Epoch 42/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5243 - accuracy: 0.7209 - val_loss: 0.5979 - val_accuracy: 0.6571\n",
      "Epoch 43/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5296 - accuracy: 0.7250 - val_loss: 0.6021 - val_accuracy: 0.6612\n",
      "Epoch 44/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5500 - accuracy: 0.7144 - val_loss: 0.5992 - val_accuracy: 0.6900\n",
      "Epoch 45/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5084 - accuracy: 0.7398 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 46/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5227 - accuracy: 0.7257 - val_loss: 0.6467 - val_accuracy: 0.6557\n",
      "Epoch 47/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5242 - accuracy: 0.7264 - val_loss: 0.5867 - val_accuracy: 0.6914\n",
      "Epoch 48/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5042 - accuracy: 0.7350 - val_loss: 0.6935 - val_accuracy: 0.6296\n",
      "Epoch 49/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5171 - accuracy: 0.7333 - val_loss: 0.6186 - val_accuracy: 0.6735\n",
      "Epoch 50/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5128 - accuracy: 0.7350 - val_loss: 0.5750 - val_accuracy: 0.6845\n",
      "Epoch 51/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4975 - accuracy: 0.7405 - val_loss: 0.5890 - val_accuracy: 0.6900\n",
      "Epoch 52/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5014 - accuracy: 0.7429 - val_loss: 0.5555 - val_accuracy: 0.7064\n",
      "Epoch 53/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4917 - accuracy: 0.7467 - val_loss: 0.5613 - val_accuracy: 0.6955\n",
      "Epoch 54/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4842 - accuracy: 0.7511 - val_loss: 0.5565 - val_accuracy: 0.6968\n",
      "Epoch 55/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4907 - accuracy: 0.7494 - val_loss: 0.5684 - val_accuracy: 0.6859\n",
      "Epoch 56/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4850 - accuracy: 0.7460 - val_loss: 0.5832 - val_accuracy: 0.6996\n",
      "Epoch 57/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4776 - accuracy: 0.7576 - val_loss: 0.6306 - val_accuracy: 0.6708\n",
      "Epoch 58/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4798 - accuracy: 0.7676 - val_loss: 0.5625 - val_accuracy: 0.7037\n",
      "Epoch 59/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4854 - accuracy: 0.7587 - val_loss: 0.5610 - val_accuracy: 0.7092\n",
      "Epoch 60/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4707 - accuracy: 0.7666 - val_loss: 0.6325 - val_accuracy: 0.6680\n",
      "Epoch 61/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4595 - accuracy: 0.7693 - val_loss: 0.5688 - val_accuracy: 0.7023\n",
      "Epoch 62/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4878 - accuracy: 0.7635 - val_loss: 0.5600 - val_accuracy: 0.7243\n",
      "Epoch 63/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4382 - accuracy: 0.7858 - val_loss: 0.6763 - val_accuracy: 0.6529\n",
      "Epoch 64/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4660 - accuracy: 0.7631 - val_loss: 0.5685 - val_accuracy: 0.6968\n",
      "Epoch 65/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4499 - accuracy: 0.7655 - val_loss: 0.5461 - val_accuracy: 0.7106\n",
      "Epoch 66/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4463 - accuracy: 0.7775 - val_loss: 0.6460 - val_accuracy: 0.6886\n",
      "Epoch 67/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4507 - accuracy: 0.7810 - val_loss: 0.5612 - val_accuracy: 0.7421\n",
      "Epoch 68/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4496 - accuracy: 0.7707 - val_loss: 0.5564 - val_accuracy: 0.7133\n",
      "Epoch 69/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4426 - accuracy: 0.7810 - val_loss: 0.6049 - val_accuracy: 0.7023\n",
      "Epoch 70/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4385 - accuracy: 0.7827 - val_loss: 0.5770 - val_accuracy: 0.7202\n",
      "Epoch 71/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4302 - accuracy: 0.7896 - val_loss: 0.5912 - val_accuracy: 0.7037\n",
      "Epoch 72/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4312 - accuracy: 0.7940 - val_loss: 0.5633 - val_accuracy: 0.7023\n",
      "Epoch 73/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4301 - accuracy: 0.7885 - val_loss: 0.5841 - val_accuracy: 0.7119\n",
      "Epoch 74/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4446 - accuracy: 0.7748 - val_loss: 0.5334 - val_accuracy: 0.7257\n",
      "Epoch 75/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4185 - accuracy: 0.7875 - val_loss: 0.6004 - val_accuracy: 0.7010\n",
      "Epoch 76/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4213 - accuracy: 0.7940 - val_loss: 0.5600 - val_accuracy: 0.7078\n",
      "Epoch 77/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4323 - accuracy: 0.7889 - val_loss: 0.6349 - val_accuracy: 0.6886\n",
      "Epoch 78/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4178 - accuracy: 0.7992 - val_loss: 0.5675 - val_accuracy: 0.7311\n",
      "Epoch 79/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4082 - accuracy: 0.7985 - val_loss: 0.5809 - val_accuracy: 0.7106\n",
      "Epoch 80/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4149 - accuracy: 0.8026 - val_loss: 0.5330 - val_accuracy: 0.7353\n",
      "Epoch 81/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4156 - accuracy: 0.8033 - val_loss: 0.7315 - val_accuracy: 0.6735\n",
      "Epoch 82/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.4074 - accuracy: 0.8009 - val_loss: 0.6123 - val_accuracy: 0.6968\n",
      "Epoch 83/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3883 - accuracy: 0.8060 - val_loss: 0.6133 - val_accuracy: 0.6955\n",
      "Epoch 84/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.3977 - accuracy: 0.8064 - val_loss: 0.5634 - val_accuracy: 0.7174\n",
      "Epoch 85/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4049 - accuracy: 0.8026 - val_loss: 0.6151 - val_accuracy: 0.7051\n",
      "Epoch 86/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.3912 - accuracy: 0.8105 - val_loss: 0.6015 - val_accuracy: 0.7257\n",
      "Epoch 87/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.3852 - accuracy: 0.8194 - val_loss: 0.6165 - val_accuracy: 0.7037\n",
      "Epoch 88/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4053 - accuracy: 0.8036 - val_loss: 0.5922 - val_accuracy: 0.7119\n",
      "Epoch 89/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3907 - accuracy: 0.8160 - val_loss: 0.7741 - val_accuracy: 0.6653\n",
      "Epoch 90/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3731 - accuracy: 0.8256 - val_loss: 0.8309 - val_accuracy: 0.6639\n",
      "Epoch 91/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3784 - accuracy: 0.8225 - val_loss: 0.6232 - val_accuracy: 0.6968\n",
      "Epoch 92/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3969 - accuracy: 0.8129 - val_loss: 0.5756 - val_accuracy: 0.7311\n",
      "Epoch 93/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3658 - accuracy: 0.8345 - val_loss: 0.5810 - val_accuracy: 0.7449\n",
      "Epoch 94/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3682 - accuracy: 0.8266 - val_loss: 0.6175 - val_accuracy: 0.7215\n",
      "Epoch 95/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3622 - accuracy: 0.8253 - val_loss: 0.6538 - val_accuracy: 0.6927\n",
      "Epoch 96/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3898 - accuracy: 0.8133 - val_loss: 0.6450 - val_accuracy: 0.7188\n",
      "Epoch 97/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3607 - accuracy: 0.8287 - val_loss: 0.5433 - val_accuracy: 0.7490\n",
      "Epoch 98/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3825 - accuracy: 0.8153 - val_loss: 0.6036 - val_accuracy: 0.7147\n",
      "Epoch 99/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3655 - accuracy: 0.8345 - val_loss: 0.5709 - val_accuracy: 0.7380\n",
      "Epoch 100/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3680 - accuracy: 0.8229 - val_loss: 0.5682 - val_accuracy: 0.7517\n",
      "Epoch 101/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3488 - accuracy: 0.8421 - val_loss: 0.5838 - val_accuracy: 0.7147\n",
      "Epoch 102/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3640 - accuracy: 0.8253 - val_loss: 0.5731 - val_accuracy: 0.7380\n",
      "Epoch 103/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3487 - accuracy: 0.8459 - val_loss: 0.5860 - val_accuracy: 0.7394\n",
      "Epoch 104/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.3488 - accuracy: 0.8387 - val_loss: 0.5991 - val_accuracy: 0.7298\n",
      "Epoch 105/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3374 - accuracy: 0.8452 - val_loss: 0.5897 - val_accuracy: 0.7353\n",
      "Epoch 106/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3307 - accuracy: 0.8500 - val_loss: 0.6021 - val_accuracy: 0.7311\n",
      "Epoch 107/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3404 - accuracy: 0.8383 - val_loss: 0.5686 - val_accuracy: 0.7325\n",
      "Epoch 108/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3492 - accuracy: 0.8380 - val_loss: 0.5713 - val_accuracy: 0.7202\n",
      "Epoch 109/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3267 - accuracy: 0.8555 - val_loss: 0.6803 - val_accuracy: 0.7188\n",
      "Epoch 110/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3166 - accuracy: 0.8586 - val_loss: 0.5914 - val_accuracy: 0.7449\n",
      "Epoch 111/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3278 - accuracy: 0.8555 - val_loss: 0.5370 - val_accuracy: 0.7654\n",
      "Epoch 112/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3391 - accuracy: 0.8452 - val_loss: 0.5948 - val_accuracy: 0.7119\n",
      "Epoch 113/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3329 - accuracy: 0.8397 - val_loss: 0.7046 - val_accuracy: 0.7380\n",
      "Epoch 114/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3232 - accuracy: 0.8479 - val_loss: 0.5644 - val_accuracy: 0.7490\n",
      "Epoch 115/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3341 - accuracy: 0.8603 - val_loss: 0.6055 - val_accuracy: 0.7366\n",
      "Epoch 116/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3279 - accuracy: 0.8472 - val_loss: 0.5979 - val_accuracy: 0.7462\n",
      "Epoch 117/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3137 - accuracy: 0.8503 - val_loss: 0.5756 - val_accuracy: 0.7517\n",
      "Epoch 118/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3294 - accuracy: 0.8637 - val_loss: 0.6333 - val_accuracy: 0.7339\n",
      "Epoch 119/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2906 - accuracy: 0.8685 - val_loss: 0.5982 - val_accuracy: 0.7449\n",
      "Epoch 120/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3289 - accuracy: 0.8483 - val_loss: 0.6335 - val_accuracy: 0.7243\n",
      "Epoch 121/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2974 - accuracy: 0.8685 - val_loss: 0.6358 - val_accuracy: 0.7435\n",
      "Epoch 122/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3014 - accuracy: 0.8661 - val_loss: 0.5633 - val_accuracy: 0.7394\n",
      "Epoch 123/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2972 - accuracy: 0.8682 - val_loss: 0.5622 - val_accuracy: 0.7531\n",
      "Epoch 124/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2901 - accuracy: 0.8689 - val_loss: 0.6285 - val_accuracy: 0.7449\n",
      "Epoch 125/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3095 - accuracy: 0.8596 - val_loss: 0.5907 - val_accuracy: 0.7298\n",
      "Epoch 126/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2796 - accuracy: 0.8785 - val_loss: 0.5999 - val_accuracy: 0.7517\n",
      "Epoch 127/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2927 - accuracy: 0.8730 - val_loss: 0.7740 - val_accuracy: 0.7119\n",
      "Epoch 128/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2958 - accuracy: 0.8774 - val_loss: 0.6346 - val_accuracy: 0.7366\n",
      "Epoch 129/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2644 - accuracy: 0.8795 - val_loss: 0.7875 - val_accuracy: 0.6927\n",
      "Epoch 130/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.3093 - accuracy: 0.8682 - val_loss: 0.6289 - val_accuracy: 0.7325\n",
      "Epoch 131/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2547 - accuracy: 0.8922 - val_loss: 0.6038 - val_accuracy: 0.7503\n",
      "Epoch 132/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2890 - accuracy: 0.8785 - val_loss: 0.6486 - val_accuracy: 0.7558\n",
      "Epoch 133/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2876 - accuracy: 0.8696 - val_loss: 0.6525 - val_accuracy: 0.7257\n",
      "Epoch 134/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2624 - accuracy: 0.8912 - val_loss: 0.6053 - val_accuracy: 0.7572\n",
      "Epoch 135/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2475 - accuracy: 0.8929 - val_loss: 0.6408 - val_accuracy: 0.7202\n",
      "Epoch 136/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2725 - accuracy: 0.8685 - val_loss: 0.6579 - val_accuracy: 0.7421\n",
      "Epoch 137/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.2803 - accuracy: 0.8747 - val_loss: 0.7282 - val_accuracy: 0.7147\n",
      "Epoch 138/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.2563 - accuracy: 0.8843 - val_loss: 0.6298 - val_accuracy: 0.7325\n",
      "Epoch 139/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2731 - accuracy: 0.8792 - val_loss: 0.5986 - val_accuracy: 0.7668\n",
      "Epoch 140/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2627 - accuracy: 0.8853 - val_loss: 0.6396 - val_accuracy: 0.7586\n",
      "Epoch 141/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.2427 - accuracy: 0.8950 - val_loss: 0.6217 - val_accuracy: 0.7545\n",
      "Epoch 142/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2618 - accuracy: 0.8816 - val_loss: 0.5951 - val_accuracy: 0.7490\n",
      "Epoch 143/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2520 - accuracy: 0.8867 - val_loss: 0.6105 - val_accuracy: 0.7531\n",
      "Epoch 144/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2409 - accuracy: 0.8956 - val_loss: 0.6374 - val_accuracy: 0.7586\n",
      "Epoch 145/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.2331 - accuracy: 0.9015 - val_loss: 0.6552 - val_accuracy: 0.7517\n",
      "Epoch 146/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.2618 - accuracy: 0.8877 - val_loss: 0.8206 - val_accuracy: 0.7229\n",
      "Epoch 147/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2282 - accuracy: 0.8994 - val_loss: 0.6225 - val_accuracy: 0.7668\n",
      "Epoch 148/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.2347 - accuracy: 0.9028 - val_loss: 0.6280 - val_accuracy: 0.7668\n",
      "Epoch 149/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.2439 - accuracy: 0.8939 - val_loss: 0.6499 - val_accuracy: 0.7545\n",
      "Epoch 150/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.2367 - accuracy: 0.8967 - val_loss: 0.6937 - val_accuracy: 0.7243\n",
      "Epoch 151/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.2277 - accuracy: 0.8998 - val_loss: 0.6634 - val_accuracy: 0.7407\n",
      "Epoch 152/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.2285 - accuracy: 0.8956 - val_loss: 0.7348 - val_accuracy: 0.7531\n",
      "Epoch 153/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2093 - accuracy: 0.9173 - val_loss: 0.7052 - val_accuracy: 0.7366\n",
      "Epoch 154/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2334 - accuracy: 0.9011 - val_loss: 0.7296 - val_accuracy: 0.7380\n",
      "Epoch 155/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.2207 - accuracy: 0.9022 - val_loss: 0.9149 - val_accuracy: 0.7174\n",
      "Epoch 156/500\n",
      "1792/2913 [=================>............] - ETA: 2s - loss: 0.2019 - accuracy: 0.9135"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=True)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weather data\n",
    "import openweather\n",
    "from datetime import datetime\n",
    "\n",
    "# create client\n",
    "ow = openweather.OpenWeather('afdc65050f1cdb2774c23cf50f0330c9')\n",
    "\n",
    "# find weather stations near me\n",
    "stations = ow.find_stations_near(\n",
    "    7.0,  # longitude\n",
    "    50.0, # latitude\n",
    "    100   # kilometer radius\n",
    ")\n",
    "\n",
    "# iterate results\n",
    "for station in stations:\n",
    "    print (station)\n",
    "\n",
    "# get current weather at Cologne/Bonn airport\n",
    "# (station id = 4885)\n",
    "print (ow.get_weather(4885))\n",
    "\n",
    "# historic weather\n",
    "start_date = datetime(2013, 09, 10)\n",
    "end_date = datetime(2013, 09, 15)\n",
    "\n",
    "# default: hourly interval\n",
    "print ow.get_historic_weather(4885, start_date, end_date)\n",
    "\n",
    "# daily aggregates\n",
    "print ow.get_historic_weather(4885, start_date, end_date, \"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST classifier\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
