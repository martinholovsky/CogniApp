{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainwave Frequencies:\n",
    "Beta, 14 to 30 Hz.  \n",
    "Alpha, 8 to 14 Hz.  \n",
    "Theta, 4 to 8 Hz.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/ML101_KS.csv . ( 1  of  16 )\n",
      "Interpolating 234/234nterpolating 28/234Interpolating 38/234Interpolating 50/234Interpolating 67/234Interpolating 91/234Interpolating 108/234Interpolating 132/234Interpolating 154/234Interpolating 168/234Interpolating 205/234Interpolating 218/234234  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML101_US.csv . ( 2  of  16 )\n",
      "224  frames generated with label  0 .224Interpolating 35/224Interpolating 64/224Interpolating 77/224Interpolating 105/224Interpolating 117/224Interpolating 137/224Interpolating 148/224Interpolating 166/224Interpolating 193/224Interpolating 204/224Interpolating 213/224\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_KS.csv . ( 3  of  16 )\n",
      "222  frames generated with label  1 .222Interpolating 101/222Interpolating 131/222Interpolating 147/222Interpolating 167/222Interpolating 179/222Interpolating 205/222\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_US.csv . ( 4  of  16 )\n",
      "Interpolating 218/218nterpolating 23/218Interpolating 41/218Interpolating 62/218Interpolating 78/218Interpolating 99/218Interpolating 116/218Interpolating 140/218Interpolating 167/218Interpolating 185/218Interpolating 199/218218  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_KS.csv . ( 5  of  16 )\n",
      "226  frames generated with label  1 .226Interpolating 71/226Interpolating 81/226Interpolating 107/226Interpolating 126/226Interpolating 157/226Interpolating 188/226Interpolating 216/226\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_US.csv . ( 6  of  16 )\n",
      "208  frames generated with label  0 .208Interpolating 18/208Interpolating 40/208Interpolating 46/208Interpolating 70/208Interpolating 102/208Interpolating 140/208Interpolating 177/208Interpolating 190/208\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_KS.csv . ( 7  of  16 )\n",
      "202  frames generated with label  1 .202Interpolating 33/202Interpolating 58/202Interpolating 72/202Interpolating 77/202Interpolating 86/202Interpolating 96/202Interpolating 118/202Interpolating 147/202Interpolating 177/202Interpolating 194/202\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_US.csv . ( 8  of  16 )\n",
      "204  frames generated with label  0 .204Interpolating 37/204Interpolating 64/204Interpolating 85/204Interpolating 105/204Interpolating 120/204Interpolating 140/204Interpolating 157/204Interpolating 172/204Interpolating 178/204Interpolating 188/204\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_KS.csv . ( 9  of  16 )\n",
      "214  frames generated with label  1 .214Interpolating 78/214Interpolating 99/214Interpolating 125/214Interpolating 155/214Interpolating 176/214Interpolating 200/214\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_US.csv . ( 10  of  16 )\n",
      "226  frames generated with label  0 .226Interpolating 44/226Interpolating 59/226Interpolating 69/226Interpolating 98/226Interpolating 123/226Interpolating 149/226Interpolating 182/226Interpolating 198/226Interpolating 218/226\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_KS.csv . ( 11  of  16 )\n",
      "230  frames generated with label  1 .230Interpolating 86/230Interpolating 121/230Interpolating 176/230Interpolating 221/230\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_US.csv . ( 12  of  16 )\n",
      "Interpolating 278/278nterpolating 97/278Interpolating 145/278Interpolating 178/278Interpolating 231/278278  frames generated with label  0 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_KS.csv . ( 13  of  16 )\n",
      "246  frames generated with label  1 .246Interpolating 78/246Interpolating 119/246Interpolating 145/246Interpolating 169/246Interpolating 202/246Interpolating 232/246\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_US.csv . ( 14  of  16 )\n",
      "236  frames generated with label  0 .236Interpolating 60/236Interpolating 79/236Interpolating 104/236Interpolating 124/236Interpolating 151/236Interpolating 174/236Interpolating 204/236Interpolating 229/236\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_KS.csv . ( 15  of  16 )\n",
      "240  frames generated with label  1 .240Interpolating 41/240Interpolating 73/240Interpolating 98/240Interpolating 129/240Interpolating 160/240Interpolating 185/240Interpolating 203/240Interpolating 229/240\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_US.csv . ( 16  of  16 )\n",
      "234  frames generated with label  0 .234Interpolating 44/234Interpolating 76/234Interpolating 95/234Interpolating 125/234Interpolating 150/234Interpolating 173/234Interpolating 195/234Interpolating 226/234\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Beta')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train_pipeline\n",
    "#from https://github.com/tevisgehr/EEG-Classification\n",
    "from eeg_learn_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4\n",
    "\n",
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta\n",
    "\n",
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals\n",
    "\n",
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]\n",
    "\n",
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN:\n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "\n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "\n",
    "    print('Generating training data...')\n",
    "\n",
    "\n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',').T\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "\n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "\n",
    "\n",
    "    return X,np.array(y)\n",
    "\n",
    "file_names = ['data/ML101_KS.csv',\n",
    "              'data/ML101_US.csv',\n",
    "              'data/ML102_KS.csv',\n",
    "              'data/ML102_US.csv',\n",
    "              'data/ML103_KS.csv',\n",
    "              'data/ML103_US.csv',\n",
    "              'data/ML104_KS.csv',\n",
    "              'data/ML104_US.csv',\n",
    "              'data/ML105_KS.csv',\n",
    "              'data/ML105_US.csv',\n",
    "              'data/ML106_KS.csv',\n",
    "              'data/ML106_US.csv',\n",
    "              'data/ML107_KS.csv',\n",
    "              'data/ML107_US.csv',\n",
    "              'data/ML108_KS.csv',\n",
    "              'data/ML108_US.csv']\n",
    "labels = [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "image_size = 28\n",
    "frame_duration = 1.0\n",
    "overlap = 0.5\n",
    "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a1964b550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "f, axarr = plt.subplots(1,3, figsize = (12,8))\n",
    "axarr[0].set_title('Theta')\n",
    "axarr[0].imshow(X[0][:,:,0], cmap='nipy_spectral')\n",
    "axarr[1].set_title('Alpha')\n",
    "axarr[1].imshow(X[0][:,:,1], cmap='nipy_spectral')\n",
    "axarr[2].set_title('Beta')\n",
    "axarr[2].imshow(X[0][:,:,2], cmap='nipy_spectral')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2913, 28, 28, 3)\n",
      "2913 train samples\n",
      "729 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ocean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/ocean/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2913 samples, validate on 729 samples\n",
      "Epoch 1/500\n",
      "2913/2913 [==============================] - 11s 4ms/step - loss: 0.7029 - accuracy: 0.5101 - val_loss: 0.6911 - val_accuracy: 0.4979\n",
      "Epoch 2/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6908 - accuracy: 0.5290 - val_loss: 0.6913 - val_accuracy: 0.5309\n",
      "Epoch 3/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6884 - accuracy: 0.5221 - val_loss: 0.6911 - val_accuracy: 0.5350\n",
      "Epoch 4/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6875 - accuracy: 0.5129 - val_loss: 0.6929 - val_accuracy: 0.4856\n",
      "Epoch 5/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6862 - accuracy: 0.5239 - val_loss: 0.6959 - val_accuracy: 0.5048\n",
      "Epoch 6/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6854 - accuracy: 0.5331 - val_loss: 0.6871 - val_accuracy: 0.4993\n",
      "Epoch 7/500\n",
      "2913/2913 [==============================] - 10s 4ms/step - loss: 0.6845 - accuracy: 0.5417 - val_loss: 0.6895 - val_accuracy: 0.5048\n",
      "Epoch 8/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6839 - accuracy: 0.5524 - val_loss: 0.6862 - val_accuracy: 0.5213\n",
      "Epoch 9/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6792 - accuracy: 0.5592 - val_loss: 0.6900 - val_accuracy: 0.5281\n",
      "Epoch 10/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6778 - accuracy: 0.5517 - val_loss: 0.6961 - val_accuracy: 0.5213\n",
      "Epoch 11/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6737 - accuracy: 0.5767 - val_loss: 0.6792 - val_accuracy: 0.5885\n",
      "Epoch 12/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6681 - accuracy: 0.5764 - val_loss: 0.6822 - val_accuracy: 0.5844\n",
      "Epoch 13/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6604 - accuracy: 0.5942 - val_loss: 0.6657 - val_accuracy: 0.6214\n",
      "Epoch 14/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6624 - accuracy: 0.5966 - val_loss: 0.6686 - val_accuracy: 0.5583\n",
      "Epoch 15/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6532 - accuracy: 0.6097 - val_loss: 0.6745 - val_accuracy: 0.5569\n",
      "Epoch 16/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6416 - accuracy: 0.6275 - val_loss: 0.6960 - val_accuracy: 0.5267\n",
      "Epoch 17/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.6512 - accuracy: 0.6042 - val_loss: 0.6547 - val_accuracy: 0.6036\n",
      "Epoch 18/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6342 - accuracy: 0.6241 - val_loss: 0.6515 - val_accuracy: 0.6118\n",
      "Epoch 19/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.6386 - accuracy: 0.6258 - val_loss: 0.6573 - val_accuracy: 0.5857\n",
      "Epoch 20/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6252 - accuracy: 0.6358 - val_loss: 0.6960 - val_accuracy: 0.5871\n",
      "Epoch 21/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6253 - accuracy: 0.6317 - val_loss: 0.6519 - val_accuracy: 0.6200\n",
      "Epoch 22/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6201 - accuracy: 0.6258 - val_loss: 0.6372 - val_accuracy: 0.6145\n",
      "Epoch 23/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6167 - accuracy: 0.6327 - val_loss: 0.6797 - val_accuracy: 0.5487\n",
      "Epoch 24/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6137 - accuracy: 0.6402 - val_loss: 0.6647 - val_accuracy: 0.6077\n",
      "Epoch 25/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.6158 - accuracy: 0.6337 - val_loss: 0.6326 - val_accuracy: 0.6159\n",
      "Epoch 26/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6055 - accuracy: 0.6498 - val_loss: 0.6542 - val_accuracy: 0.5981\n",
      "Epoch 27/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.6060 - accuracy: 0.6498 - val_loss: 0.6129 - val_accuracy: 0.6365\n",
      "Epoch 28/500\n",
      "2913/2913 [==============================] - 11s 4ms/step - loss: 0.5923 - accuracy: 0.6636 - val_loss: 0.6763 - val_accuracy: 0.6104\n",
      "Epoch 29/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.5903 - accuracy: 0.6615 - val_loss: 0.8958 - val_accuracy: 0.5309\n",
      "Epoch 30/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.6095 - accuracy: 0.6639 - val_loss: 0.7976 - val_accuracy: 0.5652\n",
      "Epoch 31/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.5741 - accuracy: 0.6756 - val_loss: 0.6391 - val_accuracy: 0.6337\n",
      "Epoch 32/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5810 - accuracy: 0.6584 - val_loss: 0.6156 - val_accuracy: 0.6392\n",
      "Epoch 33/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.5880 - accuracy: 0.6698 - val_loss: 0.6484 - val_accuracy: 0.6049\n",
      "Epoch 34/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5647 - accuracy: 0.6797 - val_loss: 0.6722 - val_accuracy: 0.6296\n",
      "Epoch 35/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.5708 - accuracy: 0.6790 - val_loss: 0.6140 - val_accuracy: 0.6571\n",
      "Epoch 36/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5695 - accuracy: 0.6814 - val_loss: 0.6222 - val_accuracy: 0.6516\n",
      "Epoch 37/500\n",
      "2913/2913 [==============================] - 11s 4ms/step - loss: 0.5724 - accuracy: 0.6845 - val_loss: 0.5979 - val_accuracy: 0.6516\n",
      "Epoch 38/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5556 - accuracy: 0.6934 - val_loss: 0.6522 - val_accuracy: 0.6447\n",
      "Epoch 39/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.5518 - accuracy: 0.6917 - val_loss: 0.5952 - val_accuracy: 0.6557\n",
      "Epoch 40/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5490 - accuracy: 0.6965 - val_loss: 0.6004 - val_accuracy: 0.6653\n",
      "Epoch 41/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5390 - accuracy: 0.7055 - val_loss: 0.6169 - val_accuracy: 0.6612\n",
      "Epoch 42/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5367 - accuracy: 0.7041 - val_loss: 0.7398 - val_accuracy: 0.5748\n",
      "Epoch 43/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5458 - accuracy: 0.7013 - val_loss: 0.6200 - val_accuracy: 0.6502\n",
      "Epoch 44/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5452 - accuracy: 0.7058 - val_loss: 0.6704 - val_accuracy: 0.6269\n",
      "Epoch 45/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5285 - accuracy: 0.7158 - val_loss: 0.5997 - val_accuracy: 0.6708\n",
      "Epoch 46/500\n",
      "2913/2913 [==============================] - 6s 2ms/step - loss: 0.5405 - accuracy: 0.7182 - val_loss: 0.5885 - val_accuracy: 0.6818\n",
      "Epoch 47/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.5136 - accuracy: 0.7295 - val_loss: 0.5773 - val_accuracy: 0.6694\n",
      "Epoch 48/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5220 - accuracy: 0.7305 - val_loss: 0.5965 - val_accuracy: 0.6680\n",
      "Epoch 49/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5144 - accuracy: 0.7199 - val_loss: 0.6044 - val_accuracy: 0.6612\n",
      "Epoch 50/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.5122 - accuracy: 0.7398 - val_loss: 0.5802 - val_accuracy: 0.6914\n",
      "Epoch 51/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5249 - accuracy: 0.7298 - val_loss: 0.6951 - val_accuracy: 0.6420\n",
      "Epoch 52/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.5059 - accuracy: 0.7285 - val_loss: 0.7476 - val_accuracy: 0.6543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.5014 - accuracy: 0.7456 - val_loss: 0.6097 - val_accuracy: 0.6763\n",
      "Epoch 54/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.5118 - accuracy: 0.7315 - val_loss: 0.6158 - val_accuracy: 0.6818\n",
      "Epoch 55/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4919 - accuracy: 0.7446 - val_loss: 0.6143 - val_accuracy: 0.6612\n",
      "Epoch 56/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4924 - accuracy: 0.7432 - val_loss: 0.5759 - val_accuracy: 0.6982\n",
      "Epoch 57/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.4897 - accuracy: 0.7535 - val_loss: 0.5691 - val_accuracy: 0.6968\n",
      "Epoch 58/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.4916 - accuracy: 0.7545 - val_loss: 0.5835 - val_accuracy: 0.6982\n",
      "Epoch 59/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.4721 - accuracy: 0.7590 - val_loss: 0.6011 - val_accuracy: 0.6900\n",
      "Epoch 60/500\n",
      "2913/2913 [==============================] - 10s 3ms/step - loss: 0.4785 - accuracy: 0.7607 - val_loss: 0.5770 - val_accuracy: 0.6859\n",
      "Epoch 61/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4652 - accuracy: 0.7648 - val_loss: 0.6104 - val_accuracy: 0.6776\n",
      "Epoch 62/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4685 - accuracy: 0.7624 - val_loss: 0.6017 - val_accuracy: 0.6667\n",
      "Epoch 63/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4866 - accuracy: 0.7563 - val_loss: 0.6617 - val_accuracy: 0.6639\n",
      "Epoch 64/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4673 - accuracy: 0.7648 - val_loss: 0.5864 - val_accuracy: 0.6694\n",
      "Epoch 65/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4709 - accuracy: 0.7628 - val_loss: 0.5738 - val_accuracy: 0.7106\n",
      "Epoch 66/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4634 - accuracy: 0.7628 - val_loss: 0.6003 - val_accuracy: 0.6900\n",
      "Epoch 67/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4556 - accuracy: 0.7727 - val_loss: 0.5969 - val_accuracy: 0.6859\n",
      "Epoch 68/500\n",
      "2913/2913 [==============================] - 9s 3ms/step - loss: 0.4539 - accuracy: 0.7645 - val_loss: 0.7365 - val_accuracy: 0.6447\n",
      "Epoch 69/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4585 - accuracy: 0.7741 - val_loss: 0.5698 - val_accuracy: 0.6886\n",
      "Epoch 70/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4483 - accuracy: 0.7820 - val_loss: 0.5737 - val_accuracy: 0.6968\n",
      "Epoch 71/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4528 - accuracy: 0.7878 - val_loss: 0.6397 - val_accuracy: 0.6818\n",
      "Epoch 72/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4434 - accuracy: 0.7813 - val_loss: 0.5726 - val_accuracy: 0.6996\n",
      "Epoch 73/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4410 - accuracy: 0.7865 - val_loss: 0.5723 - val_accuracy: 0.7078\n",
      "Epoch 74/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4330 - accuracy: 0.7841 - val_loss: 0.5871 - val_accuracy: 0.7037\n",
      "Epoch 75/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4352 - accuracy: 0.7872 - val_loss: 0.5817 - val_accuracy: 0.7147\n",
      "Epoch 76/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4228 - accuracy: 0.7964 - val_loss: 0.6070 - val_accuracy: 0.7174\n",
      "Epoch 77/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.4386 - accuracy: 0.7923 - val_loss: 0.7856 - val_accuracy: 0.6722\n",
      "Epoch 78/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4301 - accuracy: 0.7903 - val_loss: 0.6041 - val_accuracy: 0.6996\n",
      "Epoch 79/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4158 - accuracy: 0.7995 - val_loss: 0.6341 - val_accuracy: 0.6914\n",
      "Epoch 80/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4194 - accuracy: 0.8033 - val_loss: 0.5885 - val_accuracy: 0.6982\n",
      "Epoch 81/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4055 - accuracy: 0.8067 - val_loss: 0.5876 - val_accuracy: 0.7037\n",
      "Epoch 82/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4276 - accuracy: 0.7957 - val_loss: 0.5684 - val_accuracy: 0.7160\n",
      "Epoch 83/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4014 - accuracy: 0.8119 - val_loss: 0.6537 - val_accuracy: 0.6763\n",
      "Epoch 84/500\n",
      "2913/2913 [==============================] - 7s 3ms/step - loss: 0.4162 - accuracy: 0.7944 - val_loss: 0.5917 - val_accuracy: 0.6804\n",
      "Epoch 85/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4120 - accuracy: 0.7968 - val_loss: 0.6806 - val_accuracy: 0.6626\n",
      "Epoch 86/500\n",
      "2913/2913 [==============================] - 8s 3ms/step - loss: 0.4002 - accuracy: 0.8129 - val_loss: 0.6451 - val_accuracy: 0.6927\n",
      "Epoch 87/500\n",
      "2913/2913 [==============================] - 7s 2ms/step - loss: 0.3980 - accuracy: 0.8160 - val_loss: 0.5741 - val_accuracy: 0.7215\n",
      "Epoch 88/500\n",
      " 768/2913 [======>.......................] - ETA: 4s - loss: 0.3613 - accuracy: 0.8268"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b229ee1b7113>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           shuffle=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=True)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract weather data\n",
    "import openweather\n",
    "from datetime import datetime\n",
    "\n",
    "# create client\n",
    "ow = openweather.OpenWeather('afdc65050f1cdb2774c23cf50f0330c9')\n",
    "\n",
    "# find weather stations near me\n",
    "stations = ow.find_stations_near(\n",
    "    7.0,  # longitude\n",
    "    50.0, # latitude\n",
    "    100   # kilometer radius\n",
    ")\n",
    "\n",
    "# iterate results\n",
    "for station in stations:\n",
    "    print (station)\n",
    "\n",
    "# get current weather at Cologne/Bonn airport\n",
    "# (station id = 4885)\n",
    "print (ow.get_weather(4885))\n",
    "\n",
    "# historic weather\n",
    "start_date = datetime(2013, 09, 10)\n",
    "end_date = datetime(2013, 09, 15)\n",
    "\n",
    "# default: hourly interval\n",
    "print ow.get_historic_weather(4885, start_date, end_date)\n",
    "\n",
    "# daily aggregates\n",
    "print ow.get_historic_weather(4885, start_date, end_date, \"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST classifier\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
